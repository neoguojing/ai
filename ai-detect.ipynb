{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\ndef get_resnet18():\n    model = models.resnet18(pretrained=True)\n    return model\n\ndef get_vgg16():\n    model = models.vgg16(pretrained=True,weights=VGG16_Weights.IMAGENET1K_V1)\n    return model\n\ndef get_inception_v3():\n    model = models.inception_v3(pretrained=True,weights=Inception_V3_Weights.IMAGENET1K_V1)\n    return model\n\ndef get_mobilenet_v2():\n    model = models.mobilenet_v2(pretrained=True,weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n    return model\n\ndef get_densenet121():\n    model = models.densenet121(pretrained=True,weights=DenseNet121_Weights.IMAGENET1K_V1)\n    return model\n    \ndef extract_features(model, input_image_path):\n    input_image = Image.open(input_image_path)\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    input_tensor = preprocess(input_image)\n    input_batch = input_tensor.unsqueeze(0)\n\n    if torch.cuda.is_available():\n        input_batch = input_batch.cuda()\n        model.eval().cuda()\n\n    with torch.no_grad():\n        output = model(input_batch)\n    return output[0]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-21T11:49:24.536995Z","iopub.execute_input":"2023-04-21T11:49:24.538465Z","iopub.status.idle":"2023-04-21T11:49:24.549507Z","shell.execute_reply.started":"2023-04-21T11:49:24.538420Z","shell.execute_reply":"2023-04-21T11:49:24.548320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_resnet18()\noutput = extract_features(model,\"/kaggle/input/fortest/pexels-pixabay-45201.jpg\")\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:49:31.441420Z","iopub.execute_input":"2023-04-21T11:49:31.441878Z","iopub.status.idle":"2023-04-21T11:49:33.348430Z","shell.execute_reply.started":"2023-04-21T11:49:31.441836Z","shell.execute_reply":"2023-04-21T11:49:33.347210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_vgg16()\noutput1 = extract_features(model,\"/kaggle/input/fortest/pexels-pixabay-45201.jpg\")\nprint(output1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_inception_v3()\noutput2 = extract_features(model,\"/kaggle/input/fortest/pexels-pixabay-45201.jpg\")\nprint(output2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_mobilenet_v2()\noutput3 = extract_features(model,\"/kaggle/input/fortest/pexels-pixabay-45201.jpg\")\nprint(output3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_densenet121()\noutput4 = extract_features(model,\"/kaggle/input/fortest/pexels-pixabay-45201.jpg\")\nprint(output4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nfrom torchvision.models import detection\nimport torchvision\nfrom PIL import Image\nimport numpy as np\n\n\ndef load_image(image_path):\n    \"\"\"\n    Loads an image from the given file path using the PIL library.\n    \"\"\"\n    image = Image.open(image_path)\n    return image\n\n\n\n# Define RetinaNet post processor\nclass RetinaNetPostProcessor(torch.nn.Module):\n    def __init__(self, score_threshold=0.05, iou_threshold=0.5, max_detection_per_image=100):\n        super(RetinaNetPostProcessor, self).__init__()\n        self.score_threshold = score_threshold\n        self.iou_threshold = iou_threshold\n        self.max_detection_per_image = max_detection_per_image\n        self.box_coder = detection.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))\n        self.anchor_generator = detection.anchor_utils.AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),))\n        self.box_similarity = detection.box_ops.box_iou\n        self.proposal_matcher = detection.matcher.Matcher(self.iou_threshold, self.iou_threshold, allow_low_quality_matches=False)\n        self.post_processor = detection.PostProcess(self.score_threshold, self.max_detection_per_image, self.box_coder, self.box_similarity, self.proposal_matcher)\n\n    def forward(self, inputs, box_cls, box_regression):\n        anchors = self.anchor_generator(inputs)\n        detections = self.post_processor((box_cls,), (box_regression,), anchors)\n        return detections[0]\n\n\n# Define function to detect with RetinaNet\ndef detect_with_retinanet(image):\n    # Load RetinaNet model in inference mode\n    model = detection.retinanet_resnet50_fpn(pretrained=True, pretrained_backbone=True)\n    model.eval()\n    model.postprocess = RetinaNetPostProcessor()\n    # Preprocess image\n    image = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0)\n    # Perform detection\n    with torch.no_grad():\n        detections = model(image)\n    detections = model.postprocess(detections)\n    return detections\n\n# Define function to detect with FasterRCNN\ndef detect_with_fasterrcnn(image):\n    # Load FasterRCNN model in inference mode\n    model = detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=True)\n    model.eval()\n    # Preprocess image\n    image = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0)\n    # Perform detection\n    with torch.no_grad():\n        detections = model(image)\n    detections = model.postprocess(detections)\n    return detections\n    \n# Define function to detect with SSD Lite\ndef detect_with_ssd_lite(image):\n    # Load SSD Lite model in inference mode\n    model = detection.ssd_lite_mobilenet_v3_large(pretrained=True, pretrained_backbone=True)\n    model.eval()\n    # Preprocess image\n    image = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0)\n    # Perform detection\n    with torch.no_grad():\n        detections = model(image)\n    detections = model.postprocess(detections)\n    return detections\n    \n# Define function to detect with Yolov3\ndef detect_with_yolov3(image):\n    # Load Yolov3 model in inference mode\n    model = torch.hub.load('ultralytics/yolov3', 'yolov3', pretrained=True)\n    model.eval()\n    # Preprocess image\n    image = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0)\n    # Perform detection\n    with torch.no_grad():\n        detections = model(image)\n    detections = model.postprocess(detections)\n    return detections\n\nprint(torchvision.__version__)\nimage = load_image(\"/kaggle/input/fortest/pexels-pixabay-45201.jpg\")\n# Create a list of tensors from the input data\narray = np.array(image)\n\ndetect_with_retinanet(array)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:54:47.535868Z","iopub.execute_input":"2023-04-21T11:54:47.536272Z","iopub.status.idle":"2023-04-21T11:54:51.541817Z","shell.execute_reply.started":"2023-04-21T11:54:47.536239Z","shell.execute_reply":"2023-04-21T11:54:51.540254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detect_with_fasterrcnn(array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detect_with_ssd_lite(array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detect_with_yolov3(array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}