{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T11:54:47.536272Z","iopub.status.busy":"2023-04-21T11:54:47.535868Z","iopub.status.idle":"2023-04-21T11:54:51.541817Z","shell.execute_reply":"2023-04-21T11:54:51.540254Z","shell.execute_reply.started":"2023-04-21T11:54:47.536239Z"},"trusted":true},"outputs":[],"source":["# Define the function for Mask R-CNN model\n","# Import the necessary libraries\n","import torch\n","import torchvision\n","from PIL import Image\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import urllib.request\n","\n","DATASET_PREFIX = os.environ.get('DATASET_PREFIX', '')\n","IMAGENET_LABELS_FILE = DATASET_PREFIX + \"imagenet_classes.txt\"\n","CIFAR100_LABELS_FILE = DATASET_PREFIX + \"cifar100_labels.txt\"\n","CIFAR10_LABELS_FILE = DATASET_PREFIX + \"cifar10_labels.meta\"\n","PASCAL_VOC_LABELS_FILE = DATASET_PREFIX + \"pascal_voc_labels.txt\"\n","PLACES365_LABELS_FILE = DATASET_PREFIX + \"categories_places365.txt\"\n","COCO_LABELS_FILE = DATASET_PREFIX + \"coco_labels.txt\"\n","\n","def get_coco_labels():\n","    # Download the labels file from the internet\n","    if not os.path.exists(COCO_LABELS_FILE):\n","        labels_url = \"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\"\n","        urllib.request.urlretrieve(labels_url, COCO_LABELS_FILE)\n","    \n","    # Load the labels file\n","    with open(COCO_LABELS_FILE, \"r\") as f:\n","        coco_labels = f.readlines()\n","        coco_labels = [label.strip() for label in coco_labels]\n","    \n","    # Return the COCO labels\n","    return coco_labels\n","\n","# Call the function to get the labels from COCO\n","coco_labels = get_coco_labels()\n","print(coco_labels)\n","\n","def get_model(model_name):\n","    if model_name == 'maskrcnn':\n","        model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n","    elif model_name == 'yolact':\n","        model = torch.hub.load('dbolya/yolact', 'yolact_resnet50', pretrained=True)\n","    else:\n","        raise ValueError('Invalid model name')\n","    # Use GPU if available\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval() # Set model to inference mode\n","    return model\n","\n","\n","# Define the function for postprocessing\n","def postprocess(output):\n","    # Perform postprocessing on the model output\n","    # get the predicted boxes, labels, and masks for the objects in the image\n","    boxes = output[0]['boxes'].detach().numpy()\n","    labels = output[0]['labels'].detach().numpy()\n","    classs = np.array()\n","    for lable in range(labels):\n","        cls = coco_labels[lable]\n","        classs.append(cls)\n","\n","    masks = output[0]['masks'].detach().numpy()\n","\n","    print(\"boxes:\",boxes)\n","    print(\"labels:\",labels)\n","    print(\"classs:\",classs)\n","    print(\"masks:\",masks)\n","    return boxes,classs,masks\n","\n","# Define the function for instance segmentation using Mask R-CNN and YOLACT models with postprocessing\n","# Define the factory function for instance segmentation using Mask R-CNN and YOLACT models with postprocessing\n","def instance_segmentation(image_path, model_name):\n","    image = Image.open(image_path)\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    ])\n","    image = transform(image)\n","    if torch.cuda.is_available():\n","        image = image.to('cuda')\n","    \n","    model = get_model(model_name)\n","    output = None\n","    with torch.no_grad():\n","        output = model([image])\n","    \n","    print(output)\n","    \n","    boxes,labels,masks = postprocess(output)\n","    return boxes,labels,masks\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","boxes,labels,masks = instance_segmentation(\"/workspace/tests/pexels-pixabay-45201.jpg\",\"maskrcnn\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","boxes,labels,masks = instance_segmentation(\"/workspace/tests/pexels-pixabay-45201.jpg\",\"yolact\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","image = Image.open(\"/workspace/tests/pexels-pixabay-45201.jpg\")\n","transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    ])\n","image = transform(image)\n","\n","image = np.array(image.permute(1, 2, 0))\n","fig, ax = plt.subplots(1, figsize=(10, 10))\n","ax.imshow(image)\n","\n","for i in range(len(boxes)):\n","    mask = masks[i, 0]\n","    x1, y1, x2, y2 = boxes[i]\n","    width = x2 - x1\n","    height = y2 - y1\n","    ax.imshow(mask, alpha=0.5, extent=[x1, x1+width, y1, y1+height], cmap='Reds')\n","    label = labels[i]\n","    ax.text(x1, y1, f\"{label}\", fontsize=12, color='white', bbox=dict(facecolor='red', alpha=0.5, pad=0), verticalalignment='top')\n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
